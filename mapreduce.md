# mapreduce

[mapreduce论文](https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf)

## mapreduce函数

```cpp
map (k1,v1) → list(k2,v2)
reduce (k2,list(v2)) → list(v2)
```

* map: 输入记录(k1, v1)，转换成记录 (k2, v2)，这个转换过程是和上下文无关的。

* reduce: 输入记录(k2, list(v2))，其中list(v2)是map过程中同一个k值的所有相关v值聚合产生的，对每个list(v2)执行reduce过程，产生一个v2值，得到所有不同k值的结果列表，这个过程是上下文相关的。

## 实现

![overview](./img/mapreduce-impl.png)

一个典型的分布式实现如上图，可分为下列步骤：

1. 用户或者mapreduce框架把用户输入文件划分成16M-64M大小的分段，并均匀的分配到要执行计算的服务器上。

2. 用户提交mapreduce任务或者在自己的程序中创建master、worker节点。master节点用来分配任务，worker节点用来执行计算任务

3. master把map任务分配到worker当中，为了保持良好的局部性，输入文件和对应的map worker放在同一台机器上。worker读取输入文件，调用用户定义的map函数，得到中间结果，可以按照`hash(key) mod reduceNum`，把中间结果划分好保存到本地的中间输出文件，提供给对应的reduce worker使用，结束后通知master。

4. reduce worker接到master通知后，从worker上远程读取已划分好给自己的中间文件，再执行用户定义的reduce函数，得到输出结果写入到输出文件当中。

5. master得知所有的工作已经完成，从函数中返回到用户程序。

这个实现隐含了一些依赖的背景工具：

* 一个分布式文件系统，mapreduce框架需要worker频繁的在本地或者远程读取、写入文件，worker从远程读取文件，除了速度以外，应该表现得就像从本地读取文件。在google mapreduce实现中是GFS。

* 一个在master和worker间协调的分布式工具。

## 容错性

### worker故障

即使每个worker出现故障的概率很小，在大规模集群中，足够大的数量也能使得整个集群在每数分钟中都会出现worker故障。master会对所有worker做心跳检测，当发现worker有故障后，会对worker上任务的不同阶段做不同的处理。

对于map阶段的任务，中间文件是缓存在本地的，worker故障也就意味着中间文件不能被访问到了，这时候是选择把这个任务分配到其它机器上。对于reduce阶段的任务，如果任务正在进行中，将会重新分配，如果任务是已完成并且已经通知到了master，输出文件提交到了全局的文件系统中，reduce任务不会被重新分配。

### master故障

一般master可以选择定时保存暂存点，当master失败后，从暂存点恢复工作，这样能节省工作时间。但是实际上master经常是只有一台机器，失败的概率很小，从暂存点恢复带来的实现难度超过节省工作时间的收益，遇到这种情况，会直接放弃整个mapreduce任务，由客户选择是否重启这个任务。

### 原子提交

map任务和reduce任务一开始输出的是缓冲文件，这个缓冲文件属于任务进程且是随时更改的，在提交结果至master时，利用文件系统的原子命名，把这个缓冲文件重命名为提交文件的文件名，这个文件名是惟一的，避免多备份情况下出现的冲突。

### 任务形式

和纯函数类似，map、reduce任务是要求输出结果仅仅取决于输入结果，map、reduce任务执行的节点、时间或者其它因素不会影响到处理结果，这样的话能够自由的去分配节点任务。对于reduce任务，即reduce的结果不依赖输入的顺序（比如reduce任务满足交换律、reduce任务会对输入进行排序），在实际工作中，reduce任务读取所有map中间文件的顺序不是固定的，这种顺序不应该影响到reduce的输出结果。

## 局部性

在分布式系统中，带宽是宝贵的资源。在mapreduce依赖的GFS中，每个文件通常有三个备份分布在系统中不同节点上。对于无上下文依赖的map任务，要保持局部性，master尽量要做到把map任务分配到输入文件对应的备份节点上。当worker失败后，master也可以选择另外备份所在机器来重启这个map任务。

reduce任务要搜集某个特殊的key所有的map结果，不可避免的要去搜集所有中间文件。map所得到的结果，要尽可能的小，降低reduce进行远程访问的流量。必要时，可以进行shuffle过程，在map阶段执行在本地执行可以执行的reduce操作，比如word count任务时可以在map阶段就对word进行计数，reduce阶段进行各个map所得结果的聚合。

## 任务细粒度

无论是map、reduce任务，任务数量需要比worker节点数多，才能更好的调配。对于map任务，一样的输入大小，一般而言，map任务的执行时间在相同性能下是差不多的。reduce任务不一样，自然分布下，每个键对应的值的数量是很不均衡的，这也导致reduce任务的分配会很不均衡。少量的reduce任务会占用大量的时间，reduce任务的细粒度越小，更有利于整体的任务调度，更少的出现部分机器闲置等待的情况。

